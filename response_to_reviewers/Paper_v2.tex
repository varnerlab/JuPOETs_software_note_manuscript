%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
\usepackage{amsthm,amsmath}
\usepackage{graphicx}
\usepackage[margin=0.1pt,font=footnotesize,labelfont=bf]{caption}

% Imports required for p-code of JuPOETs
\usepackage[linesnumbered]{algorithm2e}
\usepackage{courier}
%\usepackage{algorithm}
\RequirePackage{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\def\includegraphic{}
\def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs
\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Software}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{JuPOETs: A Constrained Multiobjective Optimization Approach to Estimate Biochemical Model Ensembles in the Julia Programming Language}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff2},
   email={dmb457@cornell.edu}
]{\inits{DB}\fnm{David M} \snm{Bassen}}
\author[
  addressref={aff1}
]{\inits{MV}\fnm{Michael} \snm{Vilkhovoy}}
\author[
  addressref={aff1}
]{\inits{MM}\fnm{Mason} \snm{Minot}}
\author[
   addressref={aff2},
   email={jtb47@cornell.edu}
]{\inits{JB}\fnm{Jonathan T} \snm{Butcher}}
\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   corref={aff1},                       % id of corresponding address, if any
   %noteref={n1},                        % id's of article notes, if any
   email={jdv27@cornell.edu}   % email address
]{\inits{JV}\fnm{Jeffrey D} \snm{Varner}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{Department of Chemical and Biomolecular Engineering}, % university, etc
  \street{Cornell University},                     %
  \postcode{14853}                              % post or zip code
  \city{Ithaca NY},                             % city
  \cny{USA}                                    % country
}
\address[id=aff2]{%
  \orgname{Department of Biomedical Engineering},
  \street{Cornell University},                     %
  \postcode{14853}                              % post or zip code
  \city{Ithaca NY},                             % city
  \cny{USA}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
\parttitle{Background}
Ensemble modeling is a promising approach for obtaining robust predictions and coarse grained population behavior in deterministic mathematical models.
Ensemble approaches address model uncertainty by using parameter or model families instead of single best-fit parameters or fixed model structures.
Parameter ensembles can be selected based upon simulation error, along with other criteria such as diversity or steady-state performance.
Simulations using parameter ensembles can estimate confidence intervals on model variables, and robustly constrain model predictions,
despite having many poorly constrained parameters.

\parttitle{Results}
In this study, we present a multiobjective based technique to estimate parameter or models ensembles, the Pareto Optimal Ensemble Technique in the Julia programming language (JuPOETs).
JuPOETs integrates simulated annealing with Pareto optimality to estimate ensembles on or near the optimal tradeoff surface between competing training objectives.
We demonstrate JuPOETs on a suite of multiobjective problems, including test functions with parameter bounds and system constraints as well as for the identification of a proof-of-concept biochemical model with four conflicting training objectives.
JuPOETs identified optimal or near optimal solutions approximately six-fold faster than a corresponding implementation in Octave for the suite of test functions.
For the proof-of-concept biochemical model, JuPOETs produced an ensemble of parameters that gave both the mean of the training data for conflicting data sets,
while simultaneously estimating parameter sets that performed well on each of the individual objective functions.

\parttitle{Conclusions}
JuPOETs is a promising approach for the estimation of parameter and model ensembles using multiobjective optimization.
JuPOETs can be adapted to solve many problem types, including mixed binary and continuous variable types, bilevel optimization problems
and constrained problems without altering the base algorithm.
JuPOETs is open source, available under an MIT license, and can be installed using the Julia package manager from the JuPOETs GitHub repository
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{Ensemble~modeling}
\kwd{Multiobjective~optimization}
\kwd{Julia}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%

%Sethna and coworkers later showed that model performance is often controlled by only a few parameter combinations,
%a characteristic seemingly universal to multi-parameter models referred to as \textit{sloppiness} \citep{Machta:2013aa}.
%n the other hand, large models can also be constructed from many smaller modules, each of which is independently identified.
%For example, Diamond and coworkers developed a model of calcium signaling in human platelets composed of many
%separate submodels identified using different types of training data \cite{Purvis:2008}.

\section*{Background}
Ensemble modeling is a promising approach for obtaining robust predictions and coarse grained population behavior in deterministic mathematical models.
It is often not possible to uniquely identify all the parameters in biochemical models, even when given extensive training data \cite{Gadkar:2005ad}.
Thus, despite significant advances in standardizing biochemical model identification \cite{Gennemark:2009on},
the problem of estimating model parameters from experimental data remains challenging.
Ensemble approaches address parameter uncertainty in systems biology and other fields like weather prediction \cite{Battogtokh:2002,Kuepfer:2007aa, Brown:2003,Palmer:2005}
by using parameter families instead of single best-fit parameter sets.
Parameter families can be selected based upon simulation error, along with other criteria such as diversity or steady-state performance.
Simulations using parameter ensembles can estimate confidence intervals on model variables, and robustly constrain model predictions,
despite having many poorly constrained parameters \cite{Gutenkunst2007,Song:2009b}.
There are many techniques to generate parameter ensembles.
Battogtokh et al., Brown et al., and later Tasseff et al. generated experimentally constrained parameter ensembles using a
Metropolis-type random walk \cite{Battogtokh:2002,Brown:2003,Tasseff:2010aa,Tasseff:2011aa}.
Liao and coworkers developed methods to generate ensembles that all approach the same steady-state, for example one determined by fluxomics measurements \cite{Tran:2008aa}.
They have used this approach for model reduction \cite{Tan:2011aa}, strain engineering \cite{Contador2009221,Tan:2012aa} and to study the robustness of non-native pathways and network failure \cite{Lee:2014aa}.
Maranas and coworkers have also applied this method to develop a comprehensive kinetic model of bacterial central carbon metabolism,
including mutant data \cite{Khodayari:2014aa}.
We and others have used ensemble approaches, generated using both sampling and optimization techniques,
that have robustly simulated a wide variety of signal transduction processes \citep{Luan:2007aa,Song:2009aa,Tasseff:2010aa,Tasseff:2011aa,Nayak:2011aa}, neutrophil trafficking in sepsis \cite{Song:2012aa},
patient specific coagulation behavior \cite{Luan:2010aa}, uncertainty quantification in metabolic kinetic models \cite{Andreozzi:2016aa} and to capture cell to cell variation \cite{Lequieu:2011aa}. Further, ensemble approaches have been used in synthetic biology to sample possible biocircuit configurations and to design folding behaviors of novel mRNAs \cite{Otero-Muras2014,Taneda2015}.
Thus, ensemble approaches are widely used to robustly simulate a variety of biochemical systems.

Identification of biochemical models with hundreds or even thousands of states and parameters may not be tractable as a single objective optimization problem.
Further, large models require significant training data perhaps taken from diverse sources. These data often contain intrinsic conflicts resulting from, for example, the use of different cell lines or cross laboratory variability.
Parameter ensembles that optimally balance tradeoffs between submodels and conflicts in training data can
lead to robust model performance.
Multiobjective optimization is an ensemble generation technique that naturally balances conflicting training data and is preferred over single objective optimization in cases where optimizing one objective will hurt the performance of other objectives \cite{Bandyopadhyay2013}.
Previously, we developed the Pareto Optimal Ensemble Technique (POETs) algorithm to address the challenge of competing or conflicting objectives.
POETs, which integrates simulated annealing (SA) and multiobjective optimization through the notion of Pareto rank, estimates parameter ensembles which optimally trade-off between
competing (and potentially conflicting) experimental objectives \cite{Song:2010aa}.
However, the previous implementation of POETs, in the Octave programming language \cite{CITE_Octave}, suffered from poor performance and was not configurable.
For example, Octave-POETs does not accommodate user definable objective functions, bounds and problem constraints, cooling schedules, different variable types e.g., a mixture of binary and continuous design variables or custom diversity generation routines. Octave-POETs was also not well integrated into a package or
source code management (SCM) system. Thus, upgrades to the approach containing new features, or bug fixes were not centrally managed.

\section*{Implementation}
In this study, we present an open-source implementation of the Pareto optimal ensemble technique in the Julia programming language (JuPOETs).
JuPOETs offers many advantages and improvements compared to Octave-POETs.
JuPOETs takes advantage of the unique features of Julia.
Julia is a cross-platform, high-performance programming language for technical computing that has performance comparable to C but with syntax similar to MATLAB/Octave and Python \cite{Julia}. Julia also offers a sophisticated compiler, distributed parallel execution, numerical accuracy, and an extensive function library.
Further, the architecture of JuPOETs takes advantage of the first-class function type in Julia allowing user definable behavior for all key aspects of the algorithm, including objective functions, custom diversity generation logic, linear/non-linear parameter constraints (and parameter bounds constraints) as well as custom cooling schedules.
Julia's ability to naturally call other languages such as Python or C also allows JuPOETs to be used with models implemented in a variety of languages across many platforms.
Additionally, Julia offers a built-in package manager which is directly integrated with GitHub,
a popular web-based Git repository hosting service offering distributed revision control and source code management.
Thus, JuPOETs can be adapted to many problem types, including mixed binary and continuous variable types, bilevel problems and constrained problems without altering the base algorithm, as was required in the previous POETs implementation.

\subsection*{JuPOETs optimization problem formulation.}
JuPOETs solves the $\mathcal{K}-$dimensional constrained multiobjective optimization problem:
\begin{equation}
\min_{\mathbf{p}}
\begin{cases}
  O_{1}\left(\mathbf{x}(t,\mathbf{p}),\mathbf{p}\right) \\
  \vdots & \\
  O_{\mathcal{K}}\left(\mathbf{x}(t,\mathbf{p}),\mathbf{p}\right) \\
\end{cases}
\end{equation}
subject to:
\begin{eqnarray}\nonumber
  \mathbf{f}(t,\mathbf{x}(t,\mathbf{p}),\dot{\mathbf{x}}(t,\mathbf{p}),\mathbf{u}(t),\mathbf{p}) &=&\mathbf{0} \\\nonumber
  g_{1}\left(t,\mathbf{x}(t,\mathbf{p}),\mathbf{u}(t),\mathbf{p}\right) &\geq& 0 \\\nonumber
  &\vdots& \\\nonumber
  g_{\mathcal{C}}\left(t,\mathbf{x}(t,\mathbf{p}),\mathbf{u}(t),\mathbf{p}\right) &\geq& 0
\end{eqnarray}and parameter bound constraints:
\begin{equation}\nonumber
  \mathcal{L} \leq \mathbf{p} \leq \mathcal{U}
\end{equation}using a modified simulated annealing approach.
The quantity $t$ denotes time, $\mathbf{x}\left(t,\mathbf{p}\right)$ denotes the model state (with an initial state $\mathbf{x}_{0}$), and $\mathbf{u}(t)$ denotes an input vector.
The terms $\mathbf{f}(t,\mathbf{x}(t,\mathbf{p}),\dot{\mathbf{x}}(t,\mathbf{p}),\mathbf{u}(t),\mathbf{p})$ denote the system of model equations (e.g., differential equations,
differential algebraic equations or linear/non-linear algebraic equations) where $\mathbf{p}$ denotes the unknown parameter vector ($\mathcal{D}\times~1$).
The parameter search can be subject to parameter bound constraints, where $\mathcal{L}$ and $\mathcal{U}$ denote the lower and upper parameter bounds, respectively
as well as $\mathcal{C}$ problem specific constraints $g_i\left(t,\mathbf{x}(t,\mathbf{p}),\mathbf{u}(t),\mathbf{p}\right),i=1,\hdots,\mathcal{C}$.
JuPOETs integrates simulated annealing with Pareto optimality to estimate parameter sets on or near the optimal tradeoff surface between competing training objectives
(Fig. \ref{fig:fig-MOSAalgorithm} and Algorithm \ref{algo:JuPOETs-pcode}).
The central idea of POETs is a mapping between the value of the objective vector evaluated at $\mathbf{p}_{i+1}$ (parameter guess at iteration $i+1$) and Pareto rank.
JuPOETs calculates the performance of a candidate parameter set $\mathbf{p}_{i+1}$ by calling the user defined \texttt{objective} function; \texttt{objective} takes
a parameter set as an input and returns a $\mathcal{K}\times{1}$ objective vector. Candidate parameter sets are generated by the user supplied \texttt{neighbor} function.
The error vector associated with $\mathbf{p}_{i+1}$ is ranked using the builtin Pareto \texttt{rank} function, by comparing the current error at iteration $i+1$ to the error archive $\mathcal{O}_{i}$ (all error vectors up to iteration $i-1$ meeting a ranking criterion). Pareto rank is a measure of distance from the trade-off surface;
parameter sets on or near the optimal trade-off surface between the objectives have a rank equal to $0$ (no other current parameter sets are better).
These rank zero parameter sets define the Pareto optimal group for the ensemble, wherein Pareto optimality is defined as a parameter set not being dominated by any other sets within the ensemble. The surface within objective space on which these Pareto optimal parameter sets lie is called the tradeoff surface.
Sets with increasing non-zero rank are progressively further away from the optimal trade-off surface.
Thus, a parameter set with a rank $=0$ is \emph{better} in a trade-off sense than rank $>0$.
We implemented the Fonseca and Fleming ranking scheme in the builtin \texttt{rank} function \cite{RANKING}:
\begin{equation}\label{eqn_rank}
\texttt{rank}\left(\mathcal{O}_{i+1}\left(\mathbf{p}_{i+1}\right)\mid \mathcal{O}_{i}\right)=r
\end{equation} where rank $r$ is the number of parameter sets that dominate (are better than) parameter set $\mathbf{p}_{i+1}$, and $\mathcal{O}_{i+1}\left(\mathbf{p}_{i+1}\right)$
denotes the objective vector evaluated at $\mathbf{p}_{i+1}$.
We used the Pareto rank to inform the SA calculation.
The parameter set $\mathbf{p}_{i+1}$ was accepted or rejected by the SA at each iteration, by calculating an \texttt{acceptance} probability $\mathcal{P}\left(\mathbf{p}_{i+1}\right)$:
\begin{equation}\label{eqn_costMOSA}
\mathcal{P}(\mathbf{p}_{i+1}) \equiv \exp{\{-\texttt{rank}\left(\mathcal{O}_{i+1}\left(\mathbf{p}_{i+1}\right) \mid \mathcal{O}_{i} \right)/T\}}
\end{equation}
where $T$ is the computational annealing temperature that provides control over how strictly Pareto rank is enforced.
As $\texttt{rank}\left(\mathcal{O}_{i+1}\left(\mathbf{p}_{i+1}\right)\mid \mathcal{O}_{i}\right)\rightarrow{0}$, the acceptance probability moves toward one,
ensuring that we explore parameter sets along the Pareto surface.
Occasionally, (depending upon $T$) a parameter set with a high Pareto rank is  accepted by the SA allowing a more diverse search of the parameter space.
However, as $T$ is reduced, the probability of accepting a high-rank set decreases.
Parameter sets could also be accepted by the SA but $\emph{not}$ permanently archived in $\mathcal{S}_{i}$, where $\mathcal{S}_{i}$ is the solution archive.
Only parameter sets with rank less than or equal to a threshold (rank $\leq$4 by default) are included in $\mathcal{S}_{i}$, where the archive is re-ranked and filtered after accepting
every new parameter set.
Parameter bounds were implemented in the \texttt{neighbor} function as box constraints, while problem specific constraints were implemented in \texttt{objective} using a penalty method:
\begin{equation}
  O_{i}+\lambda\sum_{j=1}^{\mathcal{C}}\min\Bigl\{0,g_j\left(t,\mathbf{x}(t,\mathbf{p}),\mathbf{u}(t),\mathbf{p}\right)\Bigr\}\qquad~i=1,\hdots,\mathcal{K}
\end{equation}where $\lambda$ denotes the penalty parameter ($\lambda$ = 100 by default).
However, because both the neighbor and objective functions are user defined, different constraint implementations are easily defined.

\section*{Availability of data and materials}
JuPOETs is open source, available under an MIT software license.
The JuPOETs source code is freely available from the JuPOETs GitHub repository at https://github.com/varnerlab/POETs.jl.
All samples used in this study are included in the \texttt{sample/biochemical} and \texttt{sample/test\_functions} subdirectories of the JuPOETs GitHub repository.

\begin{algorithm}[h!]

  \SetKwFunction{objective}{objective}
  \SetKwFunction{neighbor}{neighbor}
  \SetKwFunction{acceptance}{acceptance}
  \SetKwFunction{rank}{rank}

  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{Output}

  \Input{User specified neighbor, objective, acceptance and cooling functions. Initial parameter guess ($\mathcal{D}\times~1$)}
  \Output{Rank archive $\mathcal{R}$, parameter solution archive $\mathcal{S}$ and objective archive $\mathcal{O}$}

  \BlankLine
  \BlankLine
  initialize: $\mathcal{R}$, $\mathcal{S}$ and $\mathcal{O}$ using initial guess\;
  initialize: T $\leftarrow$1.0\;
  initialize: $T_{min}\leftarrow$1/10000\;
  initialize: Maximum number of steps per temperature $\mathcal{I}$\;

  \BlankLine
  \BlankLine
 \While{$T>T_{min}$}{
    i $\leftarrow$  1\;
    \While{i$<\mathcal{I}$}{
      \BlankLine
      \BlankLine
      \tcp{Generate a new parameter solution using user neighbor function}
      $\mathbf{p}_{i+1}$ $\leftarrow$ user-function::\neighbor{$\mathbf{p}^{*}$}\;
      \BlankLine
      \BlankLine
      \tcp{Evaluate $\mathbf{p}_{i+1}$ using user objective function}
      $\mathbf{o}_{i+1}$ $\leftarrow$ user-function::\objective{$\mathbf{p}_{i+1}$}\;
      \BlankLine
      \BlankLine
      Add $\mathbf{p}_{i+1}$ to solution archive $\mathcal{S}$\;
      Add $\mathbf{o}_{i+1}$ to objective archive $\mathcal{O}$\;
      \BlankLine
      \BlankLine
      \tcp{Calculate Pareto rank of solutions in $\mathcal{O}$ using builtin rank function}
      $\mathcal{R}\leftarrow$ builtin-function::\rank{$\mathcal{O}$}\;

      \BlankLine
      \tcp{Accept $\mathbf{p}_{i+1}$ into the archive with user defined probability}
      $\mathcal{P}$ $\leftarrow$ user-function::\acceptance{$\mathcal{R}$,$T$}\;
      \eIf {$\mathcal{P}>$rand}{

          \BlankLine
          \tcp{Update the best solution with $\mathbf{p}_{i+1}$}
          $\mathbf{p}^{*}$ $\leftarrow$ $\mathbf{p}_{i+1}$\;
          prune $\mathcal{S}$, $\mathcal{R}$ and $\mathcal{O}$ of all solutions above a rank threshold\;
      }{
        Remove $\mathbf{p}_{i+1}$ from solution archive $\mathcal{S}$\;
        Remove $\mathbf{o}_{i+1}$ from error archive $\mathcal{O}$\;
      }

      \BlankLine
      i $\leftarrow$  i + 1\;
    }

    \BlankLine
    \tcp{Update $T$ using the user cooling function}
    $T$ $\leftarrow$ user-function::cooling($T$)\;
 }
\vspace{0.05in}
\caption{Pseudo-code for the main run-loop of JuPOETs.
The user specifies the \texttt{neighbor}, \texttt{acceptance}, \texttt{cooling} and \texttt{objective} functions along with an initial parameter guess.
The rank archive $\mathcal{R}$, solution archive $\mathcal{S}$ and objective archive $\mathcal{O}$ are initialized from the initial guess.
The initial guess is perturbed in the \texttt{neighbor} function, which generates a new solution whose performance is evaluated using the user supplied \texttt{objective} function.
The new solution and objective values are then added to the respective archives and ranked using the builtin \texttt{rank} function.
If the new solution is accepted (based upon a probability calculated with the user supplied \texttt{acceptance} function) it is added to the solution and objective archive.
This solution is then perturbed during the next iteration of the algorithm. However, if the solution is not accepted, it is removed from the archive and discarded. The computational temperature is adjusted using the user supplied \texttt{cooling} function after each $\mathcal{I}$ iterations. }\label{algo:JuPOETs-pcode}
\end{algorithm}


%(Fig. \ref{fig:fig-timing} and Fig. \ref{fig:fig-surfaces}).

\clearpage

\section*{Results and Discussion}

JuPOETs identified optimal or nearly optimal solutions significantly faster than Octave-POETs for a suite of multiobjective test problems (Table \ref{table:objective-table}).
The wall-clock time for JuPOETs and Octave-POETs was measured for 10 independent trials for each of the test problems.
The same \texttt{cooling}, \texttt{neighbor}, \texttt{acceptance}, and \texttt{objective} logic was employed between the implementations, and all other parameters were held constant.
For each test function, the search domain was partitioned into 10 segments, where an initial parameter guess was drawn from each partition.
The number of search steps for each temperate was $\mathcal{I}$ = 10 for all cases, and the cooling parameter was $\alpha$ = 0.9.
On average, JuPOETs identified optimal or near optimal solutions for the suite of test problems six-fold faster (60s versus 400s)
than Octave-POETs (Fig. \ref{fig:fig-timing}). JuPOETs produced the characteristic tradeoff curves for each test problem, given both parameter bound and
problem constraints (Fig. \ref{fig:fig-surfaces}).
Thus, JuPOETs estimated an ensemble of solutions to constrained multiobjective optimization test problems significantly faster than the current Octave implementation.
Next, we tested JuPOETs on a proof-of-concept biochemical model identification problem.

JuPOETs estimated an ensemble of biochemical models that was consistent with the mean of synthetic training data (Fig. \ref{fig:fig-biochemical}).
Four synthetic training data sets were generated from a prototypical biochemical network consisting of 6 metabolites and 7 reactions (Fig. \ref{fig:fig-biochemical}, inset right).
We considered a common case in which the same measurements were made on four hypothetical cell types, each having the same biological connectivity but different performance.
Network dynamics were modeled using the hybrid cybernetic model with elementary modes (HCM-EM) approach of Ramkrishna and coworkers \cite{2008_kim_varner_ramkrishna_BiotechProg}.
In the HCM-EM approach, metabolic networks are first decomposed into a set of elementary modes (EMs) (chemically balanced steady-state pathways, see \cite{Schuster:2000aa}).
Dynamic combinations of elementary modes are then used to characterize network behavior.
Each elementary mode is catalyzed by a pseudo enzyme; thus, each mode has both kinetic and enzyme synthesis parameters.
The proof of concept network generated 6 EMs, resulting in 13 model parameters.
The synthetic data was generated by randomly varying these parameters.
JuPOETs produced an ensemble of approximately $\dim{\mathcal{S}}\simeq$ 13,000 parameter sets that captured the mean of the measured data sets for extracellular metabolites and cellmass
(Fig. \ref{fig:fig-biochemical}A and B). JuPOETs minimized the difference between the simulated and measured values for extracellular metabolites A$_{e}$, B$_{e}$, C$_{e}$ and cellmass,
where the residual for each data set was treated as a single objective (leading to four objectives).
The 95\% confidence estimate produced by the ensemble was consistent with the mean of the measured data, despite having significant
uncertainty in the training data. JuPOETs produced a consensus estimate of the synthetic data by calculating optimal trade-offs between the training data sets (Fig. \ref{fig:fig-biochemical}C). Multiple trade-off fronts were visible in the objective plots, for example between data set 3 (O$_{3}$) and data set 2 (O$_{2}$).
Thus, without a multiobjective approach, it would be challenging to capture these data sets as fitting one leads to decreased performance on the other.
However, the ensemble contained parameter sets that described each data set independently (Fig. \ref{fig:fig-experiment-variation}).
Thus, JuPOETs produced an ensemble of parameters that gave the mean of the training data for conflicting data sets,
while simultaneously estimating parameter sets that performed well on each individual objective function.

\section*{Conclusions}
JuPOETs is a promising approach for the estimation of parameter and model ensembles using multiobjective optimization.
JuPOETs is a significant advance over the previous POETs implementation.
It offers improved performance and is highly adaptable to different problem types.
We demonstrated JuPOETs on a suite of test problems, and a proof-of-concept biochemical model.
However, there are several areas that could be explored further to improve JuPOETs.
First, JuPOETs should be compared with other multiobjective evolutionary algorithms (MOEAs) to determine its relative performance on test and real world problems.
Many evolutionary approaches e.g., the non-dominated sorting genetic algorithm (NSGA) family of algorithms, have been adapted to solve multiobjective optimization problems \cite{DEB2002,HUBAND2006}.
Since there is a lack of open source NSGA implementations in Julia, we were not able to compare JuPOETs to similar approaches.
One potential advantage that JuPOETs may have is the local refinement step which temporarily reduces the problem to a single objective formulation.
Previously, this hybrid approach led to better convergence on a proof-of-concept signal transduction model \cite{Song:2010aa}.
Such hybrid methods have also shown to be efficient in NSGA implementations on biochemical systems \cite{Otero-Muras2014,Sendin2006}.
For many real world parameter estimation problems, the bulk of the execution time is spent evaluating the objective functions.
One strategy to improve performance could be to optimize surrogates \cite{SURROGATES}, while another would be parallel execution of the objective functions.
Currently, JuPOETs serially evaluates the objective function vector.
However, parallel evaluation of the objective functions e.g., using the \texttt{\@parallel} Julia macro or other techniques,
could be easily implemented without changing the main run loop of JuPOETs.
Because of the flexible function pointer architecture of JuPOETs, the only changes required are in the user defined objective function.
Taken together, JuPOETs has demonstrated improved flexibility, and performance over POETs in parameter identification and ensemble generation for multiple objectives.
JuPOETs has the potential for widespread use due to the flexibility of the implementation, and the high level syntax and distribution tools native to Julia.

%However, because of the flexible function pointer architecture of JuPOETs, a shift to parallel evaluation of the objectives requires changes to the user
%defined objective function and not the main run loop. Thus, parallel evaluation of objective functions could be easily implemented
%using a variety of techniques without alterating JuPOETs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{backmatter}

\section*{Ethics approval and consent to participate}
Not applicable

\section*{Consent to publish}
Not applicable

\section*{Competing interests}
  The authors declare that they have no competing interests.

\section*{Funding}
This study was supported by an award from the National Science Foundation (NSF CBET-0955172) and the National Institutes of Health (NIH HL110328) to J.B, and by
a National Science Foundation Graduate Research Fellowship (DGE-1144153) to D.B. Lastly, J.V was supported by an award from
the US Army and Systems Biology of Trauma Induced Coagulopathy (W911NF-10-1-0376).

\section*{Author's contributions}
    J.V developed the software presented in this study. M.M and M.V developed the proof-of-concept biochemical model.
    The manuscript was prepared and edited for publication by D.B, J.B. and J.V.

\section*{Acknowledgements}
We gratefully acknowledge Ani Chakrabarti, Russell Gould and Kathy Rogers for their input and suggestions regarding new features to include into JuPOETs.
We also gratefully acknowledge the suggestions from the anonymous reviewers to improve this manuscript and JuPOETs.

\section*{Availability of data and materials}
JuPOETs is open source, available under an MIT software license.
The JuPOETs source code is freely available from the JuPOETs GitHub repository at https://github.com/varnerlab/POETs.jl.
All samples used in this study are included in the \texttt{sample/biochemical} and \texttt{sample/test\_functions} subdirectories of the JuPOETs GitHub repository.

\section*{List of abbreviations}
Not applicable

%\section*{Acknowledgements}
%  Text for this section \ldots
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{References_v1}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

\clearpage

\section*{Figures}

\begin{figure}[h]
  \caption{Schematic of multiobjective parameter mapping. The performance of any given parameter set is mapped into an objective space using a ranking function which quantifies the quality of the parameters. The distance away from the optimal tradeoff surface is quantified using the Pareto ranking scheme of Fonseca and Fleming in JuPOETs.}\label{fig:fig-MOSAalgorithm}
\end{figure}

\begin{figure}[h]
  \caption{The performance of JuPOETs on the multi-objective test suite.
  The execution time (wall-clock) for JuPOETs and POETs implemented in Octave was measured for 10 independent trials for the suite of test problems.
  The number of steps per temperature $\mathcal{I}$ = 10, and the cooling parameter $\alpha$ = 0.9 for all cases.
  The problem domain was partitioned into 10 equal segments, an initial guess was drawn from each segment.
  For each of the test functions, JuPOETs estimated solutions on (rank zero solutions, black) or near (gray) the optimal tradeoff surface, subject to bounds and problem constraints.  }\label{fig:fig-timing}
\end{figure}

\begin{figure}[h]
  \caption{Representative JuPOETs solutions for problems in the multi-objective test suite.
  The number of steps per temperature $\mathcal{I}$ = 10, and the cooling parameter $\alpha$ = 0.9 for all cases.
  The problem domain was partitioned into 10 equal segments, an initial guess was drawn from each segment.
  For each of the test functions, JuPOETs estimated solutions on (rank zero solutions, black) or near (gray) the optimal tradeoff surface, subject to bounds and problem constraints.  }\label{fig:fig-surfaces}
\end{figure}

\begin{figure}[h]
  \caption{Proof of concept biochemical network study.
  Inset right: Prototypical biochemical network with six metabolites and seven reactions modeled using the hybrid cybernetic approach (HCM).
  Intracellular cellmass precursors $A,B$, and $C$ are balanced (no accumulation) while the extracellular metabolites $A_{e},B_{e}$, and $C_{e}$ are dynamic.
  The oval denotes the cell boundary, $q_{j}$ is the $j$th flux across the boundary, and $v_{k}$ denotes the $k$th intracellular flux.
  Four data sets (each with $A_{e},B_{e}$,$C_{e}$ and cellmass measurements) were generated by varying the kinetic constants for each biochemical mode.
  Each data set was a single objective in the JuPOETs procedure.
  A: Ensemble simulation of extracellular substrate $A_{e}$ and cellmass versus time.
  B: Ensemble simulation of extracellular substrate $B_{e}$ and $C_{e}$ versus time.
  The gray region denotes the 95\% confidence estimate of the mean ensemble simulation.
  The data points denote mean synthetic measurements, while the error bars denote the 95\% confidence estimate of the measurement computed over the four training data sets.
  C: Trade-off plots between the four training objectives. The quantity $O_{j}$ denotes the jth training objective.
  Each point represents a member of the parameter ensemble, where gray denotes rank 0 sets, while black denotes rank 1 sets. Ensembles were generated using POETs without employing local refinement.
   }\label{fig:fig-biochemical}
\end{figure}

\begin{figure}[h]
  \caption{Experiment to experiment variation captured by the ensemble.
  Cellmass measurements (points) versus time for experiment 2 and 3 were compared with ensemble simulations.
  The full ensemble was sorted by simultaneously selecting the top 25\% of solutions for each objective with rank $\leq$~1.
  The best fit solution for each objective (line) $\pm$ 1-standard deviation (gray region) for experiment 2 and 3 brackets the training data despite significant differences the training values between the two data sets.}\label{fig:fig-experiment-variation}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Tables                        %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Use of \listoftables is discouraged.
%%
\clearpage
\section*{Tables}

\begin{table}
  \caption{Multi-objective optimization test problems. We tested the JuPOETs implementation on three two-dimensional test problems, with one-, two- and three-dimensional parameter vectors.
  Each problem had parameter bounds constraints, however, on the Binh and Korn function had additional non-linear problem constraints. For the Fonesca and Fleming problem, N = 3.}
  \label{table:objective-table}
\end{table}

% \begin{table}[h!]
% \caption{Sample table title. This is where the description of the table should go.}
%       \begin{tabular}{cccc}
%         \hline
%            & B1  &B2   & B3\\ \hline
%         A1 & 0.1 & 0.2 & 0.3\\
%         A2 & ... & ..  & .\\
%         A3 & ..  & .   & .\\ \hline
%       \end{tabular}
% \end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Additional Files              %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section*{Additional Files}
%   \subsection*{Additional file 1 --- Sample additional file title}
%     Additional file descriptions text (including details of how to
%     view the file, if it is in a non-standard format or the file extension).  This might
%     refer to a multi-page table or a figure.
%
%   \subsection*{Additional file 2 --- Sample additional file title}
%     Additional file descriptions text.

\end{backmatter}
\end{document}
